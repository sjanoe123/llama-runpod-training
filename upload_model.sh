#!/bin/bash

echo "ðŸ¦™ Llama 3.2 3B Model Upload Helper"
echo "===================================="
echo ""
echo "Your model needs to be uploaded to RunPod."
echo "Model size: ~6.72 GB"
echo ""
echo "Choose upload method:"
echo ""
echo "OPTION 1: Upload via Jupyter (Easiest for small files)"
echo "----------------------------------------"
echo "1. Open Jupyter at: https://YOUR_POD_ID-8888.proxy.runpod.net"
echo "2. Navigate to /workspace/"
echo "3. Create 'model' folder"
echo "4. Use upload button to upload files"
echo ""
echo "OPTION 2: Via Google Drive (Recommended for 6.72GB)"
echo "----------------------------------------"
echo "On your local machine:"
echo "  1. Compress model:"
echo "     cd /Volumes/PS2000W/.llama/checkpoints/"
echo "     tar -czf llama3.2-3b-hf.tar.gz Llama3.2-3B/"
echo "  2. Upload to Google Drive"
echo "  3. Get shareable link"
echo ""
echo "In RunPod:"
echo "  # Install gdown if needed"
echo "  pip install gdown"
echo "  "
echo "  # Download from Google Drive"
echo "  gdown 'YOUR_SHARE_LINK' -O /workspace/model.tar.gz"
echo "  "
echo "  # Extract"
echo "  cd /workspace"
echo "  tar -xzf model.tar.gz"
echo "  mv Llama3.2-3B model"
echo ""
echo "OPTION 3: Via Hugging Face Hub"
echo "----------------------------------------"
echo "  # If you have the model on HuggingFace:"
echo "  from transformers import AutoModelForCausalLM, AutoTokenizer"
echo "  "
echo "  model = AutoModelForCausalLM.from_pretrained('YOUR_HF_MODEL')"
echo "  tokenizer = AutoTokenizer.from_pretrained('YOUR_HF_MODEL')"
echo "  "
echo "  model.save_pretrained('/workspace/model')"
echo "  tokenizer.save_pretrained('/workspace/model')"
echo ""
echo "OPTION 4: Direct SCP (If you have SSH access)"
echo "----------------------------------------"
echo "From your local machine:"
echo "  scp -r /Volumes/PS2000W/.llama/checkpoints/Llama3.2-3B/ \\"
echo "      root@YOUR_POD_ID.proxy.runpod.net:/workspace/model/"
echo ""
echo "OPTION 5: Via wget from cloud storage"
echo "----------------------------------------"
echo "  # Upload to Dropbox/OneDrive/S3 first, then:"
echo "  wget 'YOUR_DIRECT_DOWNLOAD_URL' -O /workspace/model.tar.gz"
echo "  tar -xzf /workspace/model.tar.gz -C /workspace/"
echo "  mv /workspace/Llama3.2-3B /workspace/model"
echo ""
echo "===================================="
echo "After upload, verify with:"
echo "  ls -lh /workspace/model/"
echo ""
echo "Expected files:"
echo "  - config.json"
echo "  - pytorch_model.bin (or model.safetensors)"
echo "  - tokenizer.json"
echo "  - tokenizer_config.json"
echo "  - special_tokens_map.json"
echo ""